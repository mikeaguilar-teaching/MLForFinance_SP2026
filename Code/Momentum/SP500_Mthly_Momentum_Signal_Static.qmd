---
title: "Momentum Signal"
subtitle: "Constructing and evaluating a static momentum signal"
author: Mike Aguilar | https://www.linkedin.com/in/mike-aguilar-econ/ 
format: html
editor: visual
toc: true
toc-depth: 5
toc-location: left
embed-resources: true
execute: 
  warning: false
  echo: true
---

# Housekeeping

```{r}
#| echo: false
cat("\014")  # clear console
rm(list=ls())  # Clear the workspace
if (!requireNamespace("here", quietly = TRUE)) install.packages("here")
suppressPackageStartupMessages(library(here))
source(here("Supporting", "PackageLoads.R"))

```

# Data

## Load simple returns

Task: Load SP500-Monthly Simple Returns 

```{r}
Returns <- read.csv(here("Data","SP500_Mthly_SimpleReturns.csv"))
```

## Load monthly momentum from GitHub

```{r}
Momentum <- read.csv(here("Data","SP500_Mthly_Momentum.csv"))
```

## Merge

Task: Merge the returns and momentum, retaining only those dates with complete information

```{r}
merged_df <- Returns %>%
  left_join(Momentum, by = c("Date", "ticker"))

```

## Set Test and Train Periods

Task: Create a dataframe for the Train period which spans the beginning of the dataset to Aug2025. Call this dataframe Test. Create a dataframe for the Train period which is Sep2025 period. Call this dataframe Train.

```{r}

test_date <- as.Date("2025-09-30") 
last_train_date <- as.Date(
  format(test_date, "%Y-%m-01")  ) - 1

Train <- merged_df %>% filter(Date < test_date)
Train.Returns  <- Train %>% select(!momentum)
Train.Momentum <- Train %>% select(!OneMthSimpleRet)

Test <- merged_df %>% filter(Date == test_date)
Test.Returns  <- Test %>% select(!momentum)
Test.Momentum <- Test %>% select(!OneMthSimpleRet)

```

## Isolate Index and Constituents

Task: Isolate the returns for the index and the group of constituents into separate dataframes. Repeat for momentum.

```{r}
Train.Constituents <- Train %>%
  filter(!ticker == "SP500")
Train.Returns.Index <- Train.Returns %>%
  filter(ticker == "SP500")
Train.Returns.Constituents <- Train.Returns %>%
  filter(!ticker == "SP500")
Train.Momentum.Index <- Train.Momentum %>%
  filter(ticker == "SP500")
Train.Momentum.Constituents <- Train.Momentum %>%
  filter(!ticker == "SP500")

Test.Constituents <- Test %>%
  filter(!ticker == "SP500")
Test.Returns.Index <- Test.Returns %>%
  filter(ticker == "SP500")
Test.Returns.Constituents <- Test.Returns %>%
  filter(!ticker == "SP500")
Test.Momentum.Index <- Test.Momentum %>%
  filter(ticker == "SP500")
Test.Momentum.Constituents <- Test.Momentum %>%
  filter(!ticker == "SP500")

```

# Signal Construction

Task: Construct a simple momentum strategy

-   Define LongCondition = 1 if $mom^{Train}_{i} >0$ and 0 otherwise

-   Define ShortCondition = 1 if $mom^{Train}_{i} < 0$ and 0 otherwise

-   $s_{i,t}$ = LongCondition minus ShortCondition

Task: Create a vector that contains the momentum on the last observation of the training period

```{r}

Signal_Matrix <- Train.Momentum.Constituents %>% 
  filter(Date == last_train_date) %>%
  select(ticker, momentum) %>% 
  rename("signal_matrix" = "momentum")

Signal_Matrix
```

Task: Create a vector that takes +1,0,-1 based upon long, neutral, short positioning. Long of signal \> tau. Short if signal less than -tau. Neutral otherwise.

```{r}

tau <- 0

Signal_Position <- Signal_Matrix %>%
  transmute(
    ticker,
    signal = case_when(
      signal_matrix >  tau  ~  1L,
      signal_matrix < -tau  ~ -1L,
      TRUE             ~  0L
    )
  ) %>%
  rename("signal_position" = "signal")

Signal_Position

```

# Evaluate

Task: Format Test period returns to conform to the Signal Testing function

```{r}
test_returns <- Test.Returns.Constituents %>%
  select(ticker,OneMthSimpleRet) %>%
  rename(test_returns = OneMthSimpleRet)
```

Task: Create meta labels

```{r}
 Meta <- list(
   assetname = "asset",
   benchmarkname = "benchmark",
   signalname = "Momentum"
 )
```

Task: Implement the Signal Evaluation Static function

```{r}
return_threshold = 0

  SignalEval <- signal_evaluation_static(
    test_returns = test_returns,
    Meta = Meta,
    return_threshold = return_threshold,
    signal_position = Signal_Position
  )
```

Task: Display and interpret the Trade results 
```{r}
SignalEval$TradeResults_Percent
```

A: 

- No neutral signals. i.e. we traded every asset
- We had 63.7% of trades long and 36.3% short


Task: Display and interpret the hit table
```{r}
SignalEval$hit_table
```

A: 

- 56.9% of long signals were correct
- The low p value suggests that we reject the null that the Hit Rate = 0, implying that the signal has some predictive power
- Notice that the overall hit rate is the same as the Acted Only hit rate since we had no neutral signals


Task: Display and interpret the Info Coeffient 
```{r}
SignalEval$summary_ic_tbl
```
A: 

- The IC of .1534 implies that the correlation between the signal and test period returns is positive
- The small pvalue suggests that we reject the null that IC = 0, implying that the signal has predictive power over test period returns


Task: Display and interpret the confusion matrix. Focus on the Recall, Specificity, and Type 1 error for Long and Short.  
```{r}
SignalEval$confusion_report
```


A: 

- Recall for long suggests that 71% of the observations where test period returns were positive, we went long.  Meanwhile, Recall for shorts suggests that 43% of observations where test period returns were negative, we went short.  i.e. we capture more of the upside with Long than we captured the downside with Shorts. 
- specificity for long suggests that 43% of the observations with negative returns, we correctly did not long. Meanwhile specificity for shorts suggests that 71% of the observations with positive returns, we correctly did not short.  i.e. we avoid more of the bad shorts than the bad longs.  
- Notice how precision and accuracy are mirror opposites of each each in this case where we have 100% coverage. 
- Type 1 error for long suggests that in 57% of the negative test period returns we mistakenly went long.  Meanwhile the type 1 error for shorts suggests that in 29% of the positive test periods we mistakenly went short.  

